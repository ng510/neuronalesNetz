{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einfach Neuronales Netz, welches auf den FashionMNIST Daten trainiert wird\n",
    "# Vorhersage, ob das Bild ein Tshirt/Top ist, oder nicht\n",
    "# FashionMNIST: https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "def open_images(filename):\n",
    "    with gzip.open(filename, \"rb\") as file:\n",
    "        data = file.read()\n",
    "        return np.frombuffer(data, dtype=np.uint8, offset=16)\\\n",
    "            .reshape(-1, 28, 28)\\\n",
    "            .astype(np.float32)\n",
    "\n",
    "\n",
    "def open_labels(filename):\n",
    "    with gzip.open(filename, \"rb\") as file:\n",
    "        data = file.read()\n",
    "        return np.frombuffer(data, dtype=np.uint8, offset=8)\n",
    "    \n",
    "X_train = open_images(\"../data/fashion/train-images-idx3-ubyte.gz\")\n",
    "y_train = open_labels(\"../data/fashion/train-labels-idx1-ubyte.gz\")\n",
    "\n",
    "y_train = y_train == 0 #Setze alle labels auf True, falls Tshirt, sonst false\n",
    "\n",
    "X_test = open_images(\"../data/fashion/t10k-images-idx3-ubyte.gz\")\n",
    "y_test = open_labels(\"../data/fashion/t10k-labels-idx1-ubyte.gz\")\n",
    "\n",
    "y_test = y_test == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Nick\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Nick\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Nick\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Nick\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Nick\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Nick\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Nick\\.conda\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Nick\\.conda\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Nick\\.conda\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Nick\\.conda\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Nick\\.conda\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Nick\\.conda\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nick\\.conda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Ein Hidden Layer mit 100 Neuronen, danach sofort ein Neuron als Ausgang.\n",
    "#Input von 28*28 = 784 (da ein Bild 28*28 Pixel)\n",
    "model.add(Dense(100, activation=\"sigmoid\", input_shape=(784,)))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 0s 5us/step - loss: 0.0830 - accuracy: 0.9665\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 0s 5us/step - loss: 0.0826 - accuracy: 0.9660\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.0824 - accuracy: 0.9660\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.0823 - accuracy: 0.9663\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 0s 5us/step - loss: 0.0822 - accuracy: 0.9663\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.0821 - accuracy: 0.9664\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.0821 - accuracy: 0.9662\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.0820 - accuracy: 0.9666\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.0818 - accuracy: 0.9666\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.0817 - accuracy: 0.9667\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 0s 5us/step - loss: 0.0817 - accuracy: 0.9666\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 0s 5us/step - loss: 0.0816 - accuracy: 0.9667\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 0.0815 - accuracy: 0.9668\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 0s 5us/step - loss: 0.0814 - accuracy: 0.9668\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 0s 5us/step - loss: 0.0813 - accuracy: 0.9668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x295044af198>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model fitten mittels 10 Durchläufen (Epochs)\n",
    "#Gewichte anpassen nach 1000 Datensätzen (batch)\n",
    "model.fit(\n",
    "    X_train.reshape(60000, 784),\n",
    "    y_train,\n",
    "    epochs=15,\n",
    "    batch_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 18us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09625337751507759, 0.9616000056266785]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluiere Genauigkeit des Models\n",
    "#Ausgabe: ['loss', 'acc'] => Genauigkeit in Prozent im 2. Eintrag \n",
    "model.evaluate(X_test.reshape(-1, 784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAANMElEQVR4nO3db6hc9Z3H8c/Ha+KfNEhibiSa4K0lyIaVTeoQFlyKIhb1SdIHXZsHJQtKChpooQ9Wug/qQ5FtS4USSDU0K11rsRUjyG4lBKSIxTFEE427Ubnb5g+5Ey6aVNSY5NsH91hu451zxpkzc2b9vl8wzMz5zpnzvXPv587M+Z2ZnyNCAL74Lmm6AQCjQdiBJAg7kARhB5Ig7EASl45yYytWrIipqalRbhJIZXp6WqdOnfJCtYHCbvtOST+VNCHpsYh4uOz2U1NTarfbg2wSQIlWq9W11vfLeNsTkn4m6S5J6yRtsb2u3/sDMFyDvGffKOntiHg3Is5K+pWkTfW0BaBug4T9Okl/mnf9aLHsb9jeZrttu93pdAbYHIBBDBL2hXYCfObY24jYGRGtiGhNTk4OsDkAgxgk7EclrZl3fbWk44O1A2BYBgn7K5LW2v6y7cWSviVpTz1tAahb30NvEXHO9nZJ/625obddEfFGbZ0BqNVA4+wR8byk52vqBcAQcbgskARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IImBpmy2PS3pjKTzks5FRKuOpgDUb6CwF26LiFM13A+AIeJlPJDEoGEPSb+z/artbQvdwPY2223b7U6nM+DmAPRr0LDfEhFflXSXpAdsf+3iG0TEzohoRURrcnJywM0B6NdAYY+I48X5jKRnJG2soykA9es77LaX2F766WVJX5d0qK7GANRrkL3x10h6xvan9/OfEfFftXQFoHZ9hz0i3pX0DzX2AmCIGHoDkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJFEZdtu7bM/YPjRv2XLbL9g+UpwvG26bAAbVyzP7LyTdedGyByXtjYi1kvYW1wGMscqwR8SLkmYvWrxJ0u7i8m5Jm+ttC0Dd+n3Pfk1EnJCk4nxltxva3ma7bbvd6XT63ByAQQ19B11E7IyIVkS0Jicnh705AF30G/aTtldJUnE+U19LAIah37DvkbS1uLxV0rP1tANgWC6tuoHtJyXdKmmF7aOSfijpYUm/tn2vpD9K+uYwm/z/7sCBA6X1t956q7R+ww03lNbXrFnTtbZ48eLSda+++urS+jBFRGnd9og6yaEy7BGxpUvp9pp7ATBEHEEHJEHYgSQIO5AEYQeSIOxAEpV74+sUETp37lzX+sTExNC2PegwzoYNG/q+7/vuu6+0/tJLL5XW33///dJ62ZGJZ8+eLV33ww8/LK1v3LixtL558+bS+o033ti1VvW4XbhwobT+RR2aG9bPxTM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiQx0nF227r00pFusmdPP/10ab1s7HP//v0Dbfv+++8vrVd9FPTll1/uWnvnnXdK173qqqtK6zMz5d9L8thjj5XWb7rppq61e+65p3Tdyy67rLT+RVX1+646/qAbntmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAlXjenVad26dfHEE090rVeNqy5b1v9ksVU/Z9nXMUvS9PR019r1119fum7ZZ/glDfXYg/fee6+0vmPHjtL62rVrS+u33XZbaf3QoUNda6+99lrpups2bSqtVz3uGbVaLbXb7QUPCuGZHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSGOmHy2dnZ/XUU091re/bt690/TvuuKNr7dprry1dd8mSJaX17du3l9bLplWuGi+uGmevqld9j/ipU6e61s6cOdP3upJ08uTJ0vqbb75ZWj9y5EjX2unTp0vXPX78eGn99tvLJxL++OOPu9YWLVpUum6n0+n7vqXq3+kVV1zRtfbJJ5+Urlv2HQEffPBB11rlM7vtXbZnbB+at+wh28dsHyhOd1fdD4Bm9fIy/heS7lxg+U8iYn1xer7etgDUrTLsEfGipNkR9AJgiAbZQbfd9uvFy/yuB63b3ma7bbtdNa8YgOHpN+w7JH1F0npJJyT9qNsNI2JnRLQiolW2UwLAcPUV9og4GRHnI+KCpJ9LKp/qE0Dj+gq77VXzrn5DUvfPMQIYC5Xj7LaflHSrpBW2j0r6oaRbba+XFJKmJX2nl42tXr1ajzzySNf6o48+Wrr+c88917VWNV58ySXl/9eqxuEPHjzYtbZ06dLSdY8dO1Zan5qaKq33+z3hvaxbNX97Vb3qewI++uijrrWq4weqPos/yPENVduuqlf9PVV9R8GVV17ZtVb1dnflypVda2U/c2XYI2LLAosfr1oPwHjhcFkgCcIOJEHYgSQIO5AEYQeSGOlXSbdarWi320O576qPFFYN08zOlh/+X/ZRz6ohoqrezp8/X1qfmJgorZcNE1X9fsuGcaTqYcWqKZ+XL1/etXb55ZeXrls1fFX1uJXdf9XQ2eLFi0vrVR+RrRo+q1q/X3yVNADCDmRB2IEkCDuQBGEHkiDsQBKEHUhipF8lPUxVY7I333zziDoBxhPP7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSqAy77TW299k+bPsN298tli+3/YLtI8X5suG3C6BfvTyzn5P0/Yj4O0n/KOkB2+skPShpb0SslbS3uA5gTFWGPSJORMT+4vIZSYclXSdpk6Tdxc12S9o8pB4B1OBzvWe3PSVpg6Q/SLomIk5Ic/8QJC04aZjtbbbbttudTmfAdgH0q+ew2/6SpN9I+l5EnO51vYjYGRGtiGhNTk720yOAGvQUdtuLNBf0X0bEb4vFJ22vKuqrJM0Mp0UAdehlb7wlPS7pcET8eF5pj6StxeWtkp6tvz0Adenle+NvkfRtSQdtHyiW/UDSw5J+bfteSX+U9M2hdAigFpVhj4jfS1pwcndJt9fbDoBh4Qg6IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuhlfvY1tvfZPmz7DdvfLZY/ZPuY7QPF6e7htwugX73Mz35O0vcjYr/tpZJetf1CUftJRPz78NoDUJde5mc/IelEcfmM7cOSrht2YwDq9bnes9uekrRB0h+KRdttv257l+1lXdbZZrttu93pdAbrFkDfeg677S9J+o2k70XEaUk7JH1F0nrNPfP/aKH1ImJnRLQiojU5OTl4xwD60lPYbS/SXNB/GRG/laSIOBkR5yPigqSfS9o4vDYBDKqXvfGW9LikwxHx43nLV8272TckHaq/PQB16WVv/C2Svi3poO0DxbIfSNpie72kkDQt6TtD6A9ATXrZG/97SV6g9Hz97QAYFo6gA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJOGIGN3G7I6k/5u3aIWkUyNr4PMZ197GtS+J3vpVZ2/XR8SC3/820rB/ZuN2OyJajTVQYlx7G9e+JHrr16h642U8kARhB5JoOuw7G95+mXHtbVz7kuitXyPprdH37ABGp+lndgAjQtiBJBoJu+07bf+P7bdtP9hED93YnrZ9sJiGut1wL7tsz9g+NG/Zctsv2D5SnC84x15DvY3FNN4l04w3+tg1Pf35yN+z256Q9L+S7pB0VNIrkrZExJsjbaQL29OSWhHR+AEYtr8m6c+S/iMi/r5Y9oik2Yh4uPhHuSwi/nVMentI0p+bnsa7mK1o1fxpxiVtlvQvavCxK+nrnzWCx62JZ/aNkt6OiHcj4qykX0na1EAfYy8iXpQ0e9HiTZJ2F5d3a+6PZeS69DYWIuJEROwvLp+R9Ok0440+diV9jUQTYb9O0p/mXT+q8ZrvPST9zvartrc13cwCromIE9LcH4+klQ33c7HKabxH6aJpxsfmsetn+vNBNRH2haaSGqfxv1si4quS7pL0QPFyFb3paRrvUVlgmvGx0O/054NqIuxHJa2Zd321pOMN9LGgiDhenM9IekbjNxX1yU9n0C3OZxru56/GaRrvhaYZ1xg8dk1Of95E2F+RtNb2l20vlvQtSXsa6OMzbC8pdpzI9hJJX9f4TUW9R9LW4vJWSc822MvfGJdpvLtNM66GH7vGpz+PiJGfJN2tuT3y70j6tyZ66NLXDZJeK05vNN2bpCc197LuE829IrpX0tWS9ko6UpwvH6PenpB0UNLrmgvWqoZ6+yfNvTV8XdKB4nR3049dSV8jedw4XBZIgiPogCQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJvwCTGSuKSgXmoAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Grafische Ausgabe und manuelles Testen\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[30], cmap=\"gray_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00396225]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wahrscheinlichkeit, dass es sich um ein Thirt handelt\n",
    "model.predict(X_train[30].reshape(1, 784)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
